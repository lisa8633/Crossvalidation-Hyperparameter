{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Crossvalidation and hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Generalized Error on Linear Regression with k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_X, s_y = load_diabetes(return_X_y = True, as_frame = True)\n",
    "print(df_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a linear least squares regression model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_regression_model( df_X, s_y ):\n",
    "    X = df_X.values\n",
    "    X = np.insert(X,0,1,axis = 1)\n",
    "    X = pd.DataFrame(X)\n",
    "    beta_hat = np.linalg.lstsq(X,s_y)\n",
    "    beta_hat = beta_hat[0]\n",
    "    return beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-e54f273a5f5e>:5: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  beta_hat = np.linalg.lstsq(X,s_y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.18818425,  1.77890808,  0.74032569, -1.3506416 ,  0.14535984])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to check beta_hat\n",
    "np.random.seed(23)\n",
    "beta_hat = get_linear_regression_model( pd.DataFrame(np.random.random((34,4))), pd.Series(np.random.random(34)*10.0) )\n",
    "beta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  partition the dataframe and series data into dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def partition_data( df_X, s_y, k ):\n",
    "    # your code here\n",
    "    dict_x = {}\n",
    "    dict_y = {}\n",
    "\n",
    "    column = df_X.shape[0]\n",
    "    indices = np.arange(column)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    df_X = df_X[indices]\n",
    "    s_y = s_y[indices]\n",
    "    fold_x = np.array_split(df_X,k)\n",
    "    fold_y = np.array_split(s_y,k)\n",
    "    \n",
    "    for i in range(k):\n",
    "        dict_x[i] = fold_x[i]\n",
    "        dict_y[i] = fold_y[i]\n",
    "    \n",
    "    return (dict_x, dict_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_X.to_numpy()\n",
    "s_y = s_y.to_numpy()\n",
    "(dict_k_df_X, dict_k_s_y) = partition_data( df_X, s_y, 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold length of dataframe is 89 and length of series is 89\n",
      "Fold length of dataframe is 89 and length of series is 89\n",
      "Fold length of dataframe is 88 and length of series is 88\n",
      "Fold length of dataframe is 88 and length of series is 88\n",
      "Fold length of dataframe is 88 and length of series is 88\n"
     ]
    }
   ],
   "source": [
    "# Check fold sizes\n",
    "length = len(dict_k_df_X.values())\n",
    "for x in range(length):\n",
    "    print(\"Fold length of dataframe is \" + str(len(dict_k_df_X[x])) + \" and length of series is \" + str(len(dict_k_s_y[x])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate a regression metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae( s_y, s_y_hat):\n",
    "    # your code here\n",
    "    n = len(s_y)\n",
    "    MAE = 0\n",
    "    for i in range(n):\n",
    "        temp = abs(s_y[i] - s_y_hat[i]) / n\n",
    "        MAE += temp\n",
    "    return MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it \n",
    "x = np.array([1,2,3])\n",
    "y = np.array([2,2,3])\n",
    "get_mae(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the $MAE$ for each fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-e54f273a5f5e>:5: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  beta_hat = np.linalg.lstsq(X,s_y)\n"
     ]
    }
   ],
   "source": [
    "mae = np.array([])\n",
    "for k in dict_k_df_X.keys():\n",
    "\n",
    "    #set the current key as the test data\n",
    "    outer_fold_x = dict_k_df_X[k]\n",
    "    outer_fold_y = dict_k_s_y[k]\n",
    "    \n",
    "    #set the folds in each other key as the train data\n",
    "    for j in dict_k_df_X.keys():\n",
    "        if j != k:\n",
    "            inner_fold_x = dict_k_df_X[j]\n",
    "            inner_fold_y = dict_k_s_y[j]\n",
    "            #print(inner_fold_x)\n",
    "            #pd.DataFrame(inner_fold_x)\n",
    "            for i in dict_k_df_X.keys():\n",
    "                if (i != j and i !=k):\n",
    "\n",
    "                    inner_fold_x = np.append(inner_fold_x, dict_k_df_X[i], axis = 0)\n",
    "                    inner_fold_y = np.append(inner_fold_y, dict_k_s_y[i], axis = 0)\n",
    "    \n",
    "    #calculate beta hat, create matrix, then multiply for s_y_hat\n",
    "    inner_fold_x = pd.DataFrame(inner_fold_x)\n",
    "    inner_fold_y = pd.DataFrame(inner_fold_y)\n",
    "    beta_hat = get_linear_regression_model(inner_fold_x, inner_fold_y)\n",
    "    X = dict_k_df_X[k]\n",
    "    X = np.insert(X, 0, 1, axis = 1)\n",
    "\n",
    "    s_y_hat = np.matmul(X, beta_hat)\n",
    "    \n",
    "    mae = np.append( mae, get_mae(outer_fold_y,s_y_hat) )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min MAE is 41.87, the max MAE is 47.03, and the mean MAE is 44.40\n"
     ]
    }
   ],
   "source": [
    "print(\"The min MAE is {:.2f}, the max MAE is {:.2f}, and the mean MAE is {:.2f}\".format(mae.min(),mae.max(),mae.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best hyperparameter to use in a Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "df_X, s_y = load_iris(return_X_y = True, as_frame=True)\n",
    "print(len(df_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition `df_X` and `s_y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in X: \n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "Rows in Y:\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "Data Points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X = df_X.to_numpy()\n",
    "s_y = s_y.to_numpy()\n",
    "(dict_k_df_X, dict_k_s_y) = partition_data(df_X, s_y, 5)\n",
    "print(\"Rows in X: \")\n",
    "for x in dict_k_df_X.values():\n",
    "    print(len(x))\n",
    "print(\"Rows in Y:\")\n",
    "for y in dict_k_s_y.values():\n",
    "    print(len(y))\n",
    "print(\"Data Points\")\n",
    "points = 0\n",
    "for i in df_X:\n",
    "    for j in i:\n",
    "        points += 1\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc( s_1, s_2 ):\n",
    "    # your code here\n",
    "    s_1 = s_1.tolist()\n",
    "    s_2 = s_2.tolist()\n",
    "    \n",
    "    length = len(s_1)\n",
    "    acc = 0\n",
    "    for i in range(length):\n",
    "        if s_1[i] == s_2[i]:\n",
    "            acc += 1\n",
    "    return (acc/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc(s_y,np.ones(len(s_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Nested Cross validation, find the best hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Average accuracy over 4 folds is: 0.9416666666666667 2\n",
      "0.25\n",
      "Average accuracy over 4 folds is: 0.9416666666666667 2\n",
      "0.3\n",
      "Average accuracy over 4 folds is: 0.9416666666666667 2\n",
      "0.4\n",
      "Average accuracy over 4 folds is: 0.325 2\n",
      "0.1\n",
      "Average accuracy over 4 folds is: 0.9583333333333334 2\n",
      "0.25\n",
      "Average accuracy over 4 folds is: 0.875 2\n",
      "0.3\n",
      "Average accuracy over 4 folds is: 0.875 2\n",
      "0.4\n",
      "Average accuracy over 4 folds is: 0.3416666666666667 2\n",
      "0.1\n",
      "Average accuracy over 4 folds is: 0.95 2\n",
      "0.25\n",
      "Average accuracy over 4 folds is: 0.95 2\n",
      "0.3\n",
      "Average accuracy over 4 folds is: 0.6083333333333333 2\n",
      "0.4\n",
      "Average accuracy over 4 folds is: 0.2916666666666667 2\n",
      "0.1\n",
      "Average accuracy over 4 folds is: 0.9416666666666667 2\n",
      "0.25\n",
      "Average accuracy over 4 folds is: 0.85 2\n",
      "0.3\n",
      "Average accuracy over 4 folds is: 0.4833333333333333 2\n",
      "0.4\n",
      "Average accuracy over 4 folds is: 0.25 2\n",
      "0.1\n",
      "Average accuracy over 4 folds is: 0.9500000000000001 2\n",
      "0.25\n",
      "Average accuracy over 4 folds is: 0.6916666666666667 2\n",
      "0.3\n",
      "Average accuracy over 4 folds is: 0.6916666666666667 2\n",
      "0.4\n",
      "Average accuracy over 4 folds is: 0.325 2\n"
     ]
    }
   ],
   "source": [
    "possible_min_impurity_decrease = np.array([0.1,0.25,0.3,0.4])\n",
    "\n",
    "# Outer loop\n",
    "outer_accuracy = np.array([])\n",
    "for k in dict_k_df_X.keys():\n",
    "\n",
    "    # your code here\n",
    "    outer_x = dict_k_df_X[k]\n",
    "    outer_y = dict_k_s_y[k]\n",
    "    \n",
    "    for j in dict_k_df_X.keys():\n",
    "        if j != k:\n",
    "            inner_x = dict_k_df_X[j]\n",
    "            inner_y = dict_k_s_y[j]\n",
    "            for i in dict_k_df_X.keys():\n",
    "                if (i != j and i != k):\n",
    "                    inner_x= np.append(inner_x, dict_k_df_X[i], axis = 0)\n",
    "                    inner_y= np.append(inner_y, dict_k_s_y[i], axis = 0) \n",
    "\n",
    "    train_x, train_y = partition_data(inner_x, inner_y , 4)\n",
    "    min_accuracy = 0\n",
    "    min_impurity = 0\n",
    "    # Inner loop cross validation code here (use 4 folds, where the fold does not include k)\n",
    "    for pos_min_impurity in possible_min_impurity_decrease:\n",
    "        print(pos_min_impurity)\n",
    "        model = tree.DecisionTreeClassifier(criterion='gini', min_impurity_decrease = pos_min_impurity)\n",
    "        accuracy_list = []\n",
    "        for k in train_x.keys():\n",
    "            test_x = train_x[k]\n",
    "            test_y = train_y[k]\n",
    "            for j in train_x.keys():\n",
    "                if j != k:\n",
    "                    train_array_X = train_x[j]\n",
    "                    train_array_Y = train_y[j]\n",
    "                    \n",
    "                    for i in train_x.keys():\n",
    "                        if (i != j and i !=k):\n",
    "                            train_array_X= np.append(train_array_X, train_x[j], axis = 0)\n",
    "                            train_array_Y= np.append(train_array_Y, train_y[j], axis = 0)\n",
    "\n",
    "            model.fit(train_array_X, train_array_Y)\n",
    "            predicted_y = model.predict(test_x)\n",
    "            accuracy_list.append(get_acc(test_y,predicted_y))\n",
    "        accuracy_avg = sum(accuracy_list)/len(accuracy_list)\n",
    "        # Use best min impurity decrease to train model\n",
    "\n",
    "        print(\"Average accuracy over 4 folds is:\", accuracy_avg, 2)\n",
    "        \n",
    "        if accuracy_avg > min_accuracy:\n",
    "            min_accuracy = accuracy_avg\n",
    "            min_impurity = pos_min_impurity\n",
    "            \n",
    "    \n",
    "    # outer accuracy calculation \n",
    "    o_tree = tree.DecisionTreeClassifier(criterion='gini', min_impurity_decrease = min_impurity)\n",
    "    o_tree.fit(inner_x, inner_y)\n",
    "    predict_out = o_tree.predict(outer_x)\n",
    "    o_accurracy = get_acc(outer_y, predict_out)\n",
    "\n",
    "    outer_accuracy = np.append(outer_accuracy,o_accurracy) # make sure and calculate this_acc in your loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the generalized performance of the classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum accuracy of outer fold: 0.8666666666666667\n",
      "Maximum accuracy of outer fold: 0.9666666666666667\n",
      "Mean accuracy of outer fold: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum accuracy of outer fold:\", min(outer_accuracy))\n",
    "print(\"Maximum accuracy of outer fold:\", max(outer_accuracy))\n",
    "print(\"Mean accuracy of outer fold:\", sum(outer_accuracy)/len(outer_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
